# Vector dev config (reads docker logs and publishes to Kafka topic `logs.dev`).
# Minimal dev config for POC only. In production use a hardened config and
# avoid mounting the docker socket directly.

sources:
  docker:
    type: docker_logs
    # Capture from all containers for testing
    # include_containers: ["clustergenie-core-api-1", "clustergenie_core-api_1", "core-api", "clustergenie-log-consumer-1", "clustergenie_log_consumer_1", "log-consumer"]

transforms:
  filter_core_api:
    type: remap
    inputs: ["docker"]
    source: |
      # Parse message as JSON and merge in if it's an object
      parsed, perr = parse_json(.message)
      if perr == null {
        ., merr = merge(., parsed)
      }

      # Extract service from container_name
      if .container_name == "clustergenie-core-api-1" {
        .service = "core-api"
      } else if .container_name == "clustergenie-log-consumer-1" {
        .service = "log-consumer"
      } else {
        .service = "unknown"
      }

      # Set defaults
      if .environment == null {
        .environment = "dev"
      }
      if .level == null {
        .level = "info"
      }

sinks:
  kafka:
    type: kafka
    inputs: ["filter_core_api"]
    # Broker(s) reachable from inside the docker-compose network
    bootstrap_servers: "kafka:29092"
    topic: "logs.dev"
    encoding:
      codec: json
    key_field: host

  # Debug sink (prints events to the Vector container stdout). Useful for
  # quick debugging to confirm Vector is reading docker logs before we
  # rely on Kafka forwarding.
  print:
    type: console
    inputs: ["filter_core_api"]
    encoding:
      codec: json
